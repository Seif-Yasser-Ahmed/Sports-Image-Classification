{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaFlHAEs7zJb",
        "outputId": "ac2e01b1-139e-4376-dcf0-73ef36791da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchview\n",
            "  Downloading torchview-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchview) (0.20.3)\n",
            "Downloading torchview-0.2.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: torchview\n",
            "Successfully installed torchview-0.2.7\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Imports\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import inspect\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Hyperparameters\n",
        "BATCH_SIZE     = 32\n",
        "LEARNING_RATE  = 0.001\n",
        "EPOCHS         = 100\n",
        "NUM_CLASSES    = 7\n",
        "BETAS          = (0.5, 0.999)\n"
      ],
      "metadata": {
        "id": "fcJNGY1kK9wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Paths\n",
        "dataset_path   = \"/kaggle/input/sports-image-classification/dataset\"\n",
        "train_csv_path = os.path.join(dataset_path, 'train.csv')\n",
        "test_csv_path  = os.path.join(dataset_path, 'test.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-5u9DEbOYUE",
        "outputId": "c12d5c61-90b4-47a4-eb24-f723c52c8eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256, 56, 56])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Dataset class\n",
        "class SportsDataset(Dataset):\n",
        "    def __init__(self, csv_file, file_path, split='train', transform=None):\n",
        "        self.data_info = pd.read_csv(csv_file)\n",
        "        self.root_dir  = os.path.join(file_path, split)\n",
        "        self.transform = transform\n",
        "        self.split     = split\n",
        "\n",
        "        if split == 'train':\n",
        "            labels = self.data_info.iloc[:,1]\n",
        "            classes = sorted(labels.unique())\n",
        "            self.class_to_idx = {c:i for i,c in enumerate(classes)}\n",
        "            print(f\"Classes: {self.class_to_idx}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_info)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.data_info.iloc[idx,0]\n",
        "        img   = Image.open(os.path.join(self.root_dir, fname)).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.split == 'train':\n",
        "            label_str = self.data_info.iloc[idx,1]\n",
        "            return img, torch.tensor(self.class_to_idx[label_str], dtype=torch.long)\n",
        "        else:\n",
        "            return img\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na5MlLhlOa0d",
        "outputId": "cdaf4bbd-1953-4a9a-bec9-8f3daab6254e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Transforms\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "Z8hbye41Ohhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Simple conv‚ÄêReLU block\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, act='relu', drop=False, norm=True):\n",
        "        super().__init__()\n",
        "        layers = [nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)]\n",
        "        if norm:  layers.append(nn.BatchNorm2d(out_ch))\n",
        "        if act:   layers.append(nn.ReLU(inplace=True))\n",
        "        if drop:  layers.append(nn.Dropout(0.5))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "RMh7CGTmsYcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Bottleneck residual unit\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch, exp, is_bottle, stride):\n",
        "        super().__init__()\n",
        "        self.expansion = exp\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, mid_ch, 1, bias=False),\n",
        "            nn.BatchNorm2d(mid_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_ch, mid_ch, 3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_ch, mid_ch*exp, 1, bias=False),\n",
        "            nn.BatchNorm2d(mid_ch*exp),\n",
        "        )\n",
        "        if is_bottle or in_ch != mid_ch*exp:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_ch, mid_ch*exp, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(mid_ch*exp)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.residual(x)\n",
        "        out += self.shortcut(x)\n",
        "        return F.relu(out)\n"
      ],
      "metadata": {
        "id": "KKs63YqYsaAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: ResNet50 definition\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES):\n",
        "        super().__init__()\n",
        "        self.conv1   = nn.Conv2d(3,64,7,2,3,bias=False)\n",
        "        self.bn1     = nn.BatchNorm2d(64)\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(3,2,1)\n",
        "\n",
        "        self.layer1 = self._make_layer(64,  64, blocks=3, stride=1, exp=4)\n",
        "        self.layer2 = self._make_layer(256,128, blocks=4, stride=2, exp=4)\n",
        "        self.layer3 = self._make_layer(512,256, blocks=6, stride=2, exp=4)\n",
        "        self.layer4 = self._make_layer(1024,512,blocks=3, stride=2, exp=4)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc      = nn.Linear(512*4, num_classes)\n",
        "\n",
        "    def _make_layer(self, in_ch, out_ch, blocks, stride, exp):\n",
        "        layers = [Bottleneck(in_ch, out_ch, exp, True, stride)]\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(Bottleneck(out_ch*exp, out_ch, exp, False, 1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x); x = self.layer2(x)\n",
        "        x = self.layer3(x); x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "r_2AkNGssbyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Weight initialization helpers\n",
        "def xavier_init(m):\n",
        "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def init_weights(model, init_type='xavier'):\n",
        "    if init_type=='xavier':\n",
        "        model.apply(xavier_init)\n",
        "    # else if you want kaiming, define and call it here\n"
      ],
      "metadata": {
        "id": "3FI7gui8sdaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Early stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta    = delta\n",
        "        self.best     = None\n",
        "        self.counter  = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best is None or val_loss < self.best - self.delta:\n",
        "            self.best    = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n"
      ],
      "metadata": {
        "id": "s4ANKs2Hse8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Initialization routines\n",
        "def initialize_model(model_class, num_classes=NUM_CLASSES, weight_init='xavier'):\n",
        "    model = model_class(num_classes=num_classes)\n",
        "    init_weights(model, init_type=weight_init)\n",
        "    return model\n",
        "\n",
        "def initialize_optimizer(model, optimizer='adam', lr=LEARNING_RATE, betas=BETAS, wd=1e-4):\n",
        "    opts = {\n",
        "        'sgd':   lambda: optim.SGD(model.parameters(), lr=lr, momentum=betas[0], weight_decay=wd),\n",
        "        'adam':  lambda: optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=wd),\n",
        "        'adamw': lambda: optim.AdamW(model.parameters(), lr=lr, betas=betas, weight_decay=wd),\n",
        "    }\n",
        "    return opts[optimizer]()\n",
        "\n",
        "def initialize_loss_function(loss_fn='crossentropy'):\n",
        "    if loss_fn=='crossentropy':\n",
        "        return nn.CrossEntropyLoss()\n",
        "    elif loss_fn.lower().startswith('kl'):\n",
        "        return nn.KLDivLoss()\n",
        "\n",
        "def initialize_lr_scheduler(opt, scheduler_type='step', step_size=10, gamma=0.1):\n",
        "    if scheduler_type=='step':\n",
        "        return optim.lr_scheduler.StepLR(opt, step_size=step_size, gamma=gamma)\n",
        "    elif scheduler_type=='cosine':\n",
        "        return optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS, eta_min=0)\n",
        "\n",
        "def initialize_tensorboard_writer(log_dir='logs', run_name='run'):\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    return SummaryWriter(log_dir=os.path.join(log_dir, run_name))\n",
        "\n",
        "def initialize_early_stopping(patience=5, delta=0):\n",
        "    return EarlyStopping(patience=patience, delta=delta)\n",
        "\n",
        "def initialize_data_loaders(train_csv, test_csv, path, tfms):\n",
        "    train_ds = SportsDataset(train_csv, path, 'train', tfms)\n",
        "    val_ds   = SportsDataset(test_csv,  path, 'test',  tfms)\n",
        "    return (DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True),\n",
        "            DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False))\n",
        "\n",
        "def initialize_all(run_name='resnet_run'):\n",
        "    tl, vl = initialize_data_loaders(train_csv_path, test_csv_path, dataset_path, data_transforms)\n",
        "    model   = initialize_model(ResNet50)\n",
        "    opt     = initialize_optimizer(model, 'adam')\n",
        "    crit    = initialize_loss_function('crossentropy')\n",
        "    sched   = initialize_lr_scheduler(opt, scheduler_type='cosine')\n",
        "    writer  = initialize_tensorboard_writer('logs', run_name)\n",
        "    es      = initialize_early_stopping()\n",
        "    return model, opt, crit, sched, writer, es, tl, vl\n"
      ],
      "metadata": {
        "id": "HUf44r_4sghC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Training loop\n",
        "def training_loop(model, optimizer, criterion, train_loader, device, writer, num_epochs=EPOCHS):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total   = 0\n",
        "        for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(imgs)\n",
        "            loss = criterion(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "            _, preds = out.max(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total   += labels.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_acc  = correct / total\n",
        "        print(f\"Epoch {epoch+1}: Loss={epoch_loss:.4f}, Acc={epoch_acc:.4f}\")\n",
        "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
        "        writer.add_scalar('Acc/train',  epoch_acc,  epoch)\n"
      ],
      "metadata": {
        "id": "deTWFjyusie1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Kick off training\n",
        "model, optimizer, criterion, scheduler, writer, early_stopping, train_loader, val_loader = initialize_all('ResNet50_run')\n",
        "training_loop(model, optimizer, criterion, train_loader, device='cuda', writer=writer)\n"
      ],
      "metadata": {
        "id": "X7zfuoOqslaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
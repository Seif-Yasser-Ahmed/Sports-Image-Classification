{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf5cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.yaml import Config\n",
    "# from utils.optuna import run_optuna_study\n",
    "from functools import partial\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4908b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import googlenet\n",
    "class_model = googlenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f8f1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seif Yasser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Seif Yasser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Seif Yasser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class_model = class_model(pretrained=False)\n",
    "in_features = class_model.fc.in_features\n",
    "class_model.fc = nn.Linear(in_features, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e7da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='..\\\\models\\\\checkpoints\\\\modelGoogLeNet_Transfer_adam_0.01_None_32_crossentropy_wd0_epoch_7.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8d3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bdeef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: ['aux1.conv.conv.weight', 'aux1.conv.bn.weight', 'aux1.conv.bn.bias', 'aux1.conv.bn.running_mean', 'aux1.conv.bn.running_var', 'aux1.fc1.weight', 'aux1.fc1.bias', 'aux1.fc2.weight', 'aux1.fc2.bias', 'aux2.conv.conv.weight', 'aux2.conv.bn.weight', 'aux2.conv.bn.bias', 'aux2.conv.bn.running_mean', 'aux2.conv.bn.running_var', 'aux2.fc1.weight', 'aux2.fc1.bias', 'aux2.fc2.weight', 'aux2.fc2.bias']\n",
      "Unexpected keys: []\n",
      "Pretrained weights loaded into GoogLeNet successfully.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "# Check if the checkpoint is a dictionary with extra keys\n",
    "if 'model_state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "class_model.load_state_dict(state_dict=state_dict)\n",
    "class_model.to(device)\n",
    "print(\"Pretrained weights loaded into ResNet34 successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e0473",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "if 'model_state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "missing_keys, unexpected_keys = class_model.load_state_dict(state_dict, strict=False)\n",
    "print(\"Missing keys:\", missing_keys)\n",
    "print(\"Unexpected keys:\", unexpected_keys)\n",
    "class_model.to(device)\n",
    "print(\"Pretrained weights loaded into GoogLeNet successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a4ee6",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b914a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg=Config.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce54d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 32\n",
    "# LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = cfg['NUM_CLASSES']\n",
    "BETAS=cfg['BETAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d57f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Custom_Naive_adam_0.001_None_32_crossentropy_wd0',\n",
       " 'Custom_Naive_adam_0.001_None_32_KLDivLoss_wd0',\n",
       " 'Custom_Naive_adam_0.001_None_32_svm_wd0',\n",
       " 'Custom_Naive_sgd_0.1_step_32_crossentropy_wd0',\n",
       " 'Custom_Naive_sgd_0.1_cosine_32_crossentropy_wd0',\n",
       " 'Custom_Naive_rmsprop_0.1_None_32_crossentropy_wd0',\n",
       " 'Custom_Naive_rmsprop_0.01_None_32_crossentropy_wd0',\n",
       " 'Custom_Naive_rmsprop_0.1_None_16_crossentropy_wd0',\n",
       " 'Custom_Naive_rmsprop_0.01_None_16_crossentropy_wd0',\n",
       " 'Custom_Naive_adagrad_0.01_None_32_crossentropy_wd1e-6',\n",
       " 'Custom_Naive_adagrad_0.01_None_32_crossentropy_wd1e-7',\n",
       " 'ResNet_Transfer_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'ResNet_Naive_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'ResNet18_Transfer_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'ResNet34_Transfer_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'ResNet101_Transfer_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'ResNet152_Transfer_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'AlexNet_Transfer_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'AlexNet_Naive_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'GoogLeNet_Transfer_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'GoogLeNet_Naive_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'VGG16_Transfer_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'VGG16_Naive_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'VGG19_Transfer_adam_0.01_None_32_crossentropy_wd0',\n",
       " 'VGG19_Naive_adam_0.01_None_32_crossentropy_wd0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model_trainingmethod_optimizer_lr_scheduler_batch_size_lossfn_weightdecay\n",
    "run_names = cfg['run_names']\n",
    "run_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bf793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResNet18_Transfer_adam_0.01_None_32_crossentropy_wd0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_names[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d13168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = '../data/sidharkal-sports-image-classification/dataset'\n",
    "dataset_path = cfg['dataset_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cfed43",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fbe92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SportsDataset(Dataset):\n",
    "    def __init__(self, csv_file, file_path, split='train', transform=None):\n",
    "\n",
    "        self.data_info = pd.read_csv(csv_file)\n",
    "        # self.root_dir = os.path.join(file_path, split)\n",
    "        self.root_dir = os.path.join(file_path, 'train')\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        # Build string → index mapping from all labels in this split\n",
    "        # if split == 'train':\n",
    "        label_column = self.data_info.iloc[:, 1]  # assuming 2nd column is the label\n",
    "        classes = sorted(label_column.unique())\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "        print(f\"Classes: {self.class_to_idx}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1) Load image\n",
    "        img_name = os.path.join(self.root_dir, self.data_info.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        # 2) Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # if self.split=='train':\n",
    "        # 3) String label → integer index\n",
    "        label_str = self.data_info.iloc[idx, 1]\n",
    "        label_idx = self.class_to_idx[label_str]\n",
    "\n",
    "            # 4) Return image tensor, label tensor\n",
    "        return image, torch.tensor(label_idx, dtype=torch.int8)\n",
    "        # else:\n",
    "        #     # 3) Return image tensor, label tensor\n",
    "        #     return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea42da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path= os.path.join(dataset_path, 'train.csv')\n",
    "test_csv_path= os.path.join(dataset_path, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4d2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv(train_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab536e3",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c192e44",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0632905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "\n",
    "    transforms.RandomResizedCrop(\n",
    "        224,\n",
    "        scale=(0.8, 1.0),\n",
    "        ratio=(0.75, 1.3333)\n",
    "    ),\n",
    "\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1\n",
    "    ),\n",
    "    # transforms.Resize((224, 224)),  # remove if RandomResizedCrop already gives 224×224\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,act='relu',drop=False,Bnorm=True,Inorm=False,pool=False):\n",
    "        super().__init__()\n",
    "        self.drop=drop\n",
    "        self.Bnorm=Bnorm\n",
    "        self.pool=pool\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        if self.Bnorm==True:\n",
    "            self.block=nn.Sequential(\n",
    "                nn.Conv2d(in_channels,out_channels,4,2,1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU() if act=='relu' else nn.LeakyReLU(0.2),\n",
    "            )\n",
    "        elif Inorm==True:\n",
    "            self.block=nn.Sequential(\n",
    "                nn.Conv2d(in_channels,out_channels,4,2,1),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU() if act=='relu' else nn.LeakyReLU(0.2),\n",
    "            )\n",
    "        else:\n",
    "            self.block=nn.Sequential(\n",
    "                nn.Conv2d(in_channels,out_channels,4,2,1),\n",
    "                nn.ReLU() if act=='relu' else nn.LeakyReLU(0.2),\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        x=self.block(x)\n",
    "        if self.pool==True:\n",
    "            x=self.maxpool(x)\n",
    "        return self.dropout(x) if self.drop else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "973e02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7, input_channels=3, dropout=0.5,hidden_dim=64,Bnorm=True, Inorm=False,pool=True):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.Bnorm=Bnorm\n",
    "        self.Inorm=Inorm\n",
    "        self.pool=pool\n",
    "        self.block1 = Block(input_channels, hidden_dim, act='relu', drop=False, Bnorm=self.Bnorm,pool=self.pool,Inorm=self.Inorm) # 3x224x224 -> 64x112x112\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 64x112x112 -> 64x56x56\n",
    "        self.block2 = Block(hidden_dim, hidden_dim, act='relu', drop=False, Bnorm=self.Bnorm,pool=self.pool,Inorm=self.Inorm) # 64x56x56 -> 64x28x28\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 64x28x28 -> 64x14x14\n",
    "        self.block3 = Block(hidden_dim, hidden_dim*2, act='relu', drop=False, Bnorm=self.Bnorm,pool=self.pool,Inorm=self.Inorm) # 64x14x14 -> 128x7x17\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128x7x7 -> 128x3x3\n",
    "        self.block4 = Block(hidden_dim*2, hidden_dim*2, act='relu', drop=False, Bnorm=self.Bnorm,pool=self.pool,Inorm=self.Inorm) \n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2) # 128x3x3 -> 128x1x1\n",
    "        self.fc1 = nn.Linear(128, 128)  #  128 -> 128\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(128, num_classes) # 128 -> num_classes\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc3 = nn.Linear(128*3*3, 128) # 128 -> num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14781d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e976b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CustomCNN(num_classes=NUM_CLASSES,Bnorm=True,Inorm=False,pool=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b731d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
